{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.optimize\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_mldata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "First get and preprocess the data. This time, we will use the complete data set and not just the samples for the numbers **`0`** and **`1`**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data: contains 70k samples of which the last 10k are meant for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist = fetch_mldata('MNIST original', data_home='./data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare for concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_all = mnist.target[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intercept term to be added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intercept = np.ones_like(y_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the next step, we need to define this util function which normalizes the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_features(train, test):\n",
    "    \"\"\"Normalizes train set features to a standard normal distribution\n",
    "    (zero mean and unit variance). The same procedure is then applied\n",
    "    to the test set features.\n",
    "    \"\"\"\n",
    "    train_mean = train.mean(axis=0)\n",
    "    # +0.1 to avoid division by zero in this specific case\n",
    "    train_std = train.std(axis=0) + 0.1\n",
    "    \n",
    "    train = (train - train_mean) / train_std\n",
    "    test = (test - train_mean) / train_std\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, normalize the data (zero mean and unit variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_normalized, test_normalized = normalize_features(\n",
    "    mnist.data[:60000, :],\n",
    "    mnist.data[60000:, :],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concat **`intercept`**, **`X`**, and **`y`** so that shuffling is easier in a next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_all = np.hstack((\n",
    "    intercept[:60000],\n",
    "    train_normalized,\n",
    "    y_all[:60000],\n",
    "))\n",
    "test_all = np.hstack((\n",
    "    intercept[60000:],\n",
    "    test_normalized,\n",
    "    y_all[60000:],\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle the data. As mentioned in the [Logistic_Regression](http://nbviewer.ipython.org/github/HaFl/ufldl-tutorial-python/blob/master/Logistic_Regression.ipynb) notebook already, I don't think it's needed, but let's stick with the ufldl tutorial here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(train_all)\n",
    "np.random.shuffle(test_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, get train and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = train_all[:, :-1]\n",
    "train_y = train_all[:, -1]\n",
    "\n",
    "test_X = test_all[:, :-1]    \n",
    "test_y = test_all[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some helpful variables and initial random theta values for all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m, n = train_X.shape\n",
    "k = np.unique(train_y).size\n",
    "theta = np.random.rand(n, k) * 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This **`indicator_mask`** will come in handy when computing the gradient later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indicator_mask = np.zeros((train_X.shape[0], theta.shape[1]), dtype=np.bool)\n",
    "for i, idx in enumerate(train_y):\n",
    "    indicator_mask[i][idx] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a helper function to keep the code DRY. It computes the probabilities of all classes for all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def probs(theta, X, y):\n",
    "    if theta.ndim == 1:\n",
    "        theta = theta.reshape((theta.size / k, k))\n",
    "    values = np.exp(X.dot(theta)) \n",
    "    sums = np.sum(values, axis=1)\n",
    "    return (values.T / sums).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost function of Softmax Regression. We could actually use the **`indicator_mask`** here instead of the loop at the end, but that would be computational overkill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cost_function(theta, X, y):\n",
    "    log_probs = np.log(probs(theta, X, y))\n",
    "    cost = 0\n",
    "    for i in range(m):\n",
    "         cost -= log_probs[i][y[i]] / m\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient function of Softmax Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gradient(theta, X, y):\n",
    "    gradient_matrix = - (1.0 / m) * X.T.dot(indicator_mask - probs(theta, X, y))\n",
    "    return gradient_matrix.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, let's run the optimization. 100 iterations are enough here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization took 179.322736025 seconds\n"
     ]
    }
   ],
   "source": [
    "J_history = []\n",
    "\n",
    "t0 = time.time()\n",
    "res = scipy.optimize.minimize(\n",
    "    fun=cost_function,\n",
    "    x0=theta,\n",
    "    args=(train_X, train_y),\n",
    "    method='L-BFGS-B',\n",
    "    jac=gradient,\n",
    "    options={'maxiter': 100, 'disp': True},\n",
    "    callback=lambda x: J_history.append(cost_function(x, train_X, train_y)),\n",
    ")\n",
    "t1 = time.time()\n",
    "\n",
    "print('Optimization took {s} seconds'.format(s=t1 - t0))\n",
    "optimal_theta = res.x.reshape((theta.size / k, k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the evolution of **`J`** (to make sure we did the right thing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x10d02e610>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEPCAYAAACp/QjLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHA5mZlbk/wPWzB0Yrwv7ygAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114719250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(J_history, marker='o')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('J(theta)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even the **`optimal_theta`** still results in a relatively high cost value **`J`**. That's not necessarily a bad sign, but rather the consequence of the model being more complex than e.g., Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(theta, X, y):\n",
    "    correct = np.sum(np.argmax(probs(theta, X, y), axis=1) == y)\n",
    "    return float(correct) / y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.943616666667\n",
      "Test accuracy: 0.9239\n"
     ]
    }
   ],
   "source": [
    "print('Training accuracy: {acc}'.format(acc=accuracy(res.x, train_X, train_y)))\n",
    "print('Test accuracy: {acc}'.format(acc=accuracy(res.x, test_X, test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
